# ğŸ“š Handwritten Digit Classifier

## ğŸ“– Overview
This project predicts **handwritten digit classes (0â€“9)** using the **MNIST dataset** and a convolutional neural network (**CNN**) built with **PyTorch**.  
It demonstrates a full machine learning pipeline from data loading to inference, including:

- ğŸ§  **CNN** with stacked convolutional layers, **Batch Normalization**, **Max Pooling**, **LeakyReLU** activation, and **Dropout**  
- âš–ï¸ **Cross-Entropy Loss** for multi-class classification  
- ğŸš€ **Adam optimizer** for gradient updates  
- ğŸ”€ **Mini-batch training** with `DataLoader`  
- ğŸ“Š **Train/Validation/Test split** for robust evaluation  
- ğŸ“ˆ **Live training & validation loss monitoring**  
- âœ… **Softmax activation** on the output for probability distribution across 10 classes

---

## ğŸ§© Libraries
- **PyTorch** â€“ model, training, and inference  
- **pandas** â€“ data handling  
- **matplotlib** â€“ loss visualization  
- **pickle** â€“ saving/loading normalization params and trained model

---

## âš™ï¸ Requirements

- Python **3.13+**
- Recommended editor: **VS Code**

---

## ğŸ“¦ Installation

- Clone the repository
```bash
git clone https://github.com/hurkanugur/Handwritten-Digit-Classifier.git
```

- Navigate to the `Handwritten-Digit-Classifier` directory
```bash
cd Handwritten-Digit-Classifier
```

- Install dependencies
```bash
pip install -r requirements.txt
```

- Navigate to the `Handwritten-Digit-Classifier/src` directory
```bash
cd src
```

---

## ğŸ”§ Setup Python Environment in VS Code

1. `View â†’ Command Palette â†’ Python: Create Environment`  
2. Choose **Venv** and your **Python version**  
3. Select **requirements.txt** to install dependencies  
4. Click **OK**

---

## ğŸ“‚ Project Structure

```bash
data/
â””â”€â”€ MNIST                             # MNIST dataset (raw greyscale images and labels)
â””â”€â”€ test_data                         # Sample images for inference

model/
â””â”€â”€ mnist_digit_classifier.pth        # Trained model (after training)

src/
â”œâ”€â”€ config.py                         # Paths, hyperparameters, split ratios
â”œâ”€â”€ dataset.py                        # Data loading & preprocessing
â”œâ”€â”€ device_manager.py                 # Selects and manages compute device
â”œâ”€â”€ main_train.py                     # Training & model saving
â”œâ”€â”€ main_inference.py                 # Inference pipeline
â”œâ”€â”€ model.py                          # Neural network definition
â”œâ”€â”€ visualize.py                      # Training/validation plots

requirements.txt                      # Python dependencies
```

---

## ğŸ“‚ Model Architecture

```bash
Input (1Ã—28Ã—28)

Conv Block 1:
  â†’ Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1, padding_mode="reflect")
  â†’ BatchNorm2d(32)
  â†’ ReLU
  â†’ MaxPool2d(kernel_size=2, stride=2)
  â†’ Dropout(0.25)

Conv Block 2:
  â†’ Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, padding_mode="reflect")
  â†’ BatchNorm2d(64)
  â†’ ReLU
  â†’ MaxPool2d(kernel_size=2, stride=2)
  â†’ Dropout(0.25)

Fully Connected:
  â†’ Flatten
  â†’ Linear(64Ã—7Ã—7, 128)
  â†’ ReLU
  â†’ BatchNorm1d(128)
  â†’ Dropout(0.5)
  â†’ Linear(128, 10)
  â†’ Softmax(Output)
```

---

## ğŸ“‚ Train the Model
```bash
python main_train.py
```
or
```bash
python3 main_train.py
```

---

## ğŸ“‚ Run Predictions on Real Data
```bash
python main_inference.py
```
or
```bash
python3 main_inference.py
```
