# ğŸ“š MNIST Handwritten Digit Classifier

## ğŸ“– Overview
This project predicts **handwritten digit classes (0â€“9)** using the **MNIST dataset** and a convolutional neural network (**CNN**) built with **PyTorch**. It demonstrates a full machine learning pipeline from data loading to inference, including:

- ğŸ§  **CNN** with stacked convolutional layers, **Batch Normalization**, **Max Pooling**, **LeakyReLU** activation, and **Dropout**  
- âš–ï¸ **Cross-Entropy Loss** for multi-class classification  
- ğŸš€ **Adam optimizer** for gradient updates  
- ğŸ”€ **Mini-batch training** with `DataLoader`  
- ğŸ“Š **Train/Validation/Test split** for robust evaluation  
- ğŸ“ˆ **Live training & validation loss monitoring**  
- âœ… **Softmax activation** on the output for probability distribution across 10 classes
- ğŸ¨ **Interactive Gradio Interface** for real-time prediction

---

## ğŸ–¼ï¸ Application Screenshot

Below is a preview of the **Gradio Interface** used for real-time classification:

![Application Screenshot](assets/app_screenshot.png)

---

## ğŸ§© Libraries
- **PyTorch** â€“ model, training, and inference  
- **pandas** â€“ data handling  
- **matplotlib** â€“ loss visualization  
- **pickle** â€“ saving/loading normalization params and trained model
- **Gradio** â€” interactive web interface for real-time model demos 

---

## âš™ï¸ Requirements

- Python **3.13+**
- Recommended editor: **VS Code**

---

## ğŸ“¦ Installation

- Clone the repository
```bash
git clone https://github.com/hurkanugur/MNIST-Digit-Classifier.git
```

- Navigate to the `MNIST-Digit-Classifier` directory
```bash
cd MNIST-Digit-Classifier
```

- Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ”§ Setup Python Environment in VS Code

1. `View â†’ Command Palette â†’ Python: Create Environment`  
2. Choose **Venv** and your **Python version**  
3. Select **requirements.txt** to install dependencies  
4. Click **OK**

---

## ğŸ“‚ Project Structure

```bash
assets/
â”œâ”€â”€ app_screenshot.png                # Screenshot of the application
â””â”€â”€ 1, 2, 3 ... 9.png                 # Digit samples

data/
â””â”€â”€ MNIST                             # MNIST dataset

model/
â””â”€â”€ mnist_digit_classifier.pth        # Trained model

src/
â”œâ”€â”€ config.py                         # Paths, hyperparameters, split ratios
â”œâ”€â”€ dataset.py                        # Data loading & preprocessing
â”œâ”€â”€ device_manager.py                 # Selects and manages compute device
â”œâ”€â”€ train.py                          # Training pipeline
â”œâ”€â”€ inference.py                      # Inference pipeline
â”œâ”€â”€ model.py                          # Neural network definition
â””â”€â”€ visualize.py                      # Training/validation plots

main/
â”œâ”€â”€ main_train.py                     # Entry point for training
â””â”€â”€ main_inference.py                 # Entry point for inference

requirements.txt                      # Python dependencies
```

---

## ğŸ“‚ Model Architecture

```bash
Input (1Ã—28Ã—28)

Conv Block 1:
  â†’ Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1, padding_mode="reflect")
  â†’ BatchNorm2d(32)
  â†’ ReLU
  â†’ MaxPool2d(kernel_size=2, stride=2)
  â†’ Dropout(0.25)

Conv Block 2:
  â†’ Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, padding_mode="reflect")
  â†’ BatchNorm2d(64)
  â†’ ReLU
  â†’ MaxPool2d(kernel_size=2, stride=2)
  â†’ Dropout(0.25)

Fully Connected:
  â†’ Flatten
  â†’ Linear(64Ã—7Ã—7, 128)
  â†’ ReLU
  â†’ BatchNorm1d(128)
  â†’ Dropout(0.5)
  â†’ Linear(128, 10)
  â†’ Softmax(Output)
```

---

## ğŸ“‚ Train the Model
Navigate to the project directory:
```bash
cd MNIST-Digit-Classifier
```

Run the training script:
```bash
python -m main.main_train
```
or
```bash
python3 -m main.main_train
```

---

## ğŸ“‚ Run Inference / Make Predictions
Navigate to the project directory:
```bash
cd MNIST-Digit-Classifier
```

Run the app:
```bash
python -m main.main_inference
```
or
```bash
python3 -m main.main_inference
```
